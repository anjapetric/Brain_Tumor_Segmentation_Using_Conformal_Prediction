{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary libraries\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import PIL\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from skimage import data\n",
    "from skimage.util import montage \n",
    "import skimage.transform as skTrans\n",
    "from skimage.transform import rotate\n",
    "from skimage.transform import resize\n",
    "from PIL import Image, ImageOps  \n",
    "\n",
    "\n",
    "# neural imaging\n",
    "import nilearn as nl\n",
    "import nibabel as nib\n",
    "import nilearn.plotting as nlplt\n",
    "# !pip install git+https://github.com/miykael/gif_your_nifti # nifti to gif \n",
    "# import gif_your_nifti.core as gif2nif\n",
    "\n",
    "\n",
    "# ml libs\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.layers import Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "#from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "# Make numpy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE seg-areas  \n",
    "SEGMENT_CLASSES = {\n",
    "    0 : 'NOT tumor',\n",
    "    1 : 'NECROTIC/CORE', # or NON-ENHANCING tumor CORE\n",
    "    2 : 'EDEMA',\n",
    "    3 : 'ENHANCING' # original 4 -> converted into 3 later\n",
    "}\n",
    "\n",
    "# there are 155 slices per volume\n",
    "# to start at 5 and use 145 slices means we will skip the first 5 and last 5 \n",
    "VOLUME_SLICES = 100 \n",
    "VOLUME_START_AT = 22 # first slice of volume that we will include\n",
    "IMG_SIZE=128\n",
    "\n",
    "TRAIN_DATASET_PATH = os.path.join(os.getcwd(), 'BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/')\n",
    "VALIDATION_DATASET_PATH = os.path.join(os.getcwd(), 'BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Tumor Segmentation Classifier Starts Here \n",
    "\n",
    "## Base model from Kaggle see https://www.kaggle.com/code/rastislav/3d-mri-brain-tumor-segmentation-u-net made by Ratislav KopÃ¡l\n",
    "## (Adjusted to required specification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dice loss as defined above for 4 classes\n",
    "def dice_coef(y_true, y_pred, smooth=1.0):\n",
    "    class_num = 4\n",
    "    for i in range(class_num):\n",
    "        y_true_f = K.flatten(y_true[:,:,:,i])\n",
    "        y_pred_f = K.flatten(y_pred[:,:,:,i])\n",
    "        intersection = K.sum(y_true_f * y_pred_f)\n",
    "        loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n",
    "   #     K.print_tensor(loss, message='loss value for class {} : '.format(SEGMENT_CLASSES[i]))\n",
    "        if i == 0:\n",
    "            total_loss = loss\n",
    "        else:\n",
    "            total_loss = total_loss + loss\n",
    "    total_loss = total_loss / class_num\n",
    "#    K.print_tensor(total_loss, message=' total dice coef: ')\n",
    "    return total_loss\n",
    "\n",
    "\n",
    " \n",
    "# define per class evaluation of dice coef\n",
    "# inspired by https://github.com/keras-team/keras/issues/9395\n",
    "def dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,1] * y_pred[:,:,:,1]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,1])) + K.sum(K.square(y_pred[:,:,:,1])) + epsilon)\n",
    "\n",
    "def dice_coef_edema(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,2] * y_pred[:,:,:,2]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,2])) + K.sum(K.square(y_pred[:,:,:,2])) + epsilon)\n",
    "\n",
    "def dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,3] * y_pred[:,:,:,3]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,3])) + K.sum(K.square(y_pred[:,:,:,3])) + epsilon)\n",
    "\n",
    "# Computing Precision \n",
    "def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "# Computing Sensitivity      \n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "# Computing Specificity\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source https://naomi-fridman.medium.com/multi-class-image-segmentation-a5cc671e647a\n",
    "\n",
    "def build_unet(inputs, ker_init, dropout):\n",
    "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(inputs)\n",
    "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv1)\n",
    "    \n",
    "    pool = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool)\n",
    "    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv2)\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv3)\n",
    "    \n",
    "    \n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool4)\n",
    "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv5)\n",
    "    drop5 = Dropout(dropout)(conv5)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n",
    "    \n",
    "    up = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv9))\n",
    "    merge = concatenate([conv1,up], axis = 3)\n",
    "    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge)\n",
    "    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n",
    "    \n",
    "    conv10 = Conv2D(4, (1,1), activation = 'softmax')(conv)\n",
    "    \n",
    "    return Model(inputs = inputs, outputs = conv10)\n",
    "\n",
    "input_layer = Input((IMG_SIZE, IMG_SIZE, 2))\n",
    "\n",
    "model = build_unet(input_layer, 'he_normal', 0.2)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists of directories with studies\n",
    "train_and_val_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n",
    "\n",
    "# file BraTS20_Training_355 has ill formatted name for for seg.nii file\n",
    "train_and_val_directories.remove(TRAIN_DATASET_PATH+'BraTS20_Training_355')\n",
    "\n",
    "def pathListIntoIds(dirList):\n",
    "    x = []\n",
    "    for i in range(0,len(dirList)):\n",
    "        x.append(dirList[i][dirList[i].rfind('/')+1:])\n",
    "    return x\n",
    "\n",
    "train_and_test_ids = pathListIntoIds(train_and_val_directories); \n",
    "\n",
    "print(f'total number of pre-labeled MRI scans: {len(train_and_test_ids)}')\n",
    "# Seperate data into 80% model build, 20% Validation\n",
    "train_test_ids, val_ids = train_test_split(train_and_test_ids,test_size=0.2) \n",
    "# 50% of training data to train NN, 50% of training data to calibrate conformal framework, MUCH less is required for conformal framework to hold\n",
    "model_ids, conformal_ids = train_test_split(train_test_ids,test_size=0.5)\n",
    "# Split NN training date into 85% train, 15% test\n",
    "train_ids, test_ids = train_test_split(model_ids,test_size=0.15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = 2, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n",
    "        y = np.zeros((self.batch_size*VOLUME_SLICES, 240, 240))\n",
    "        Y = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, 4))\n",
    "\n",
    "        \n",
    "        # Generate data\n",
    "        for c, i in enumerate(Batch_ids):\n",
    "            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_flair.nii');\n",
    "            flair = nib.load(data_path).get_fdata()    \n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_t1ce.nii');\n",
    "            ce = nib.load(data_path).get_fdata()\n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_seg.nii');\n",
    "            seg = nib.load(data_path).get_fdata()\n",
    "        \n",
    "            for j in range(VOLUME_SLICES):\n",
    "                 X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
    "                 X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
    "\n",
    "                 y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n",
    "                    \n",
    "        # Generate masks\n",
    "        y[y==4] = 3;\n",
    "        mask = tf.one_hot(y, 4);\n",
    "        Y = tf.image.resize(mask, (IMG_SIZE, IMG_SIZE));\n",
    "        return X/np.max(X), Y\n",
    "        \n",
    "training_generator = DataGenerator(train_ids)\n",
    "valid_generator = DataGenerator(val_ids)\n",
    "test_generator = DataGenerator(test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We import pretrained weights to save time, uncomment to self train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger('training.log', separator=',', append=False)\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "#     keras.callbacks.EarlyStopping(monitor='loss', min_delta=0,\n",
    "#                               patience=2, verbose=1, mode='auto'),\n",
    "      keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=2, min_lr=0.000001, verbose=1),\n",
    "#  keras.callbacks.ModelCheckpoint(filepath = 'model_.{epoch:02d}-{val_loss:.6f}.m5',\n",
    "#                             verbose=1, save_best_only=True, save_weights_only = True)\n",
    "        csv_logger\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# history =  model.fit(training_generator,\n",
    "#                     epochs=35,\n",
    "#                     steps_per_epoch=len(train_ids),\n",
    "#                     callbacks= callbacks,\n",
    "#                     validation_data = valid_generator\n",
    "#                     )  \n",
    "# model.save(\"model_x1_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ load trained model ################\n",
    "model = keras.models.load_model(os.path.join(os.getcwd(), 'model_per_class.h5'), \n",
    "                                   custom_objects={ 'accuracy' : tf.keras.metrics.MeanIoU(num_classes=4),\n",
    "                                                   \"dice_coef\": dice_coef,\n",
    "                                                   \"precision\": precision,\n",
    "                                                   \"sensitivity\":sensitivity,\n",
    "                                                   \"specificity\":specificity,\n",
    "                                                   \"dice_coef_necrotic\": dice_coef_necrotic,\n",
    "                                                   \"dice_coef_edema\": dice_coef_edema,\n",
    "                                                   \"dice_coef_enhancing\": dice_coef_enhancing\n",
    "                                                  }, compile=False)\n",
    "\n",
    "history = pd.read_csv(os.path.join(os.getcwd(), 'training_per_class.log'), sep=',', engine='python')\n",
    "\n",
    "hist=history\n",
    "\n",
    "############### ########## ####### #######\n",
    "\n",
    "# hist=history.history\n",
    "\n",
    "acc=hist['accuracy']\n",
    "val_acc=hist['val_accuracy']\n",
    "\n",
    "epoch=range(len(acc))\n",
    "\n",
    "loss=hist['loss']\n",
    "val_loss=hist['val_loss']\n",
    "\n",
    "train_dice=hist['dice_coef']\n",
    "val_dice=hist['val_dice_coef']\n",
    "\n",
    "f,ax=plt.subplots(1,4,figsize=(16,8))\n",
    "\n",
    "ax[0].plot(epoch,acc,'b',label='Training Accuracy')\n",
    "ax[0].plot(epoch,val_acc,'r',label='Validation Accuracy')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(epoch,loss,'b',label='Training Loss')\n",
    "ax[1].plot(epoch,val_loss,'r',label='Validation Loss')\n",
    "ax[1].legend()\n",
    "\n",
    "ax[2].plot(epoch,train_dice,'b',label='Training dice coef')\n",
    "ax[2].plot(epoch,val_dice,'r',label='Validation dice coef')\n",
    "ax[2].legend()\n",
    "\n",
    "ax[3].plot(epoch,hist['mean_io_u'],'b',label='Training mean IOU')\n",
    "ax[3].plot(epoch,hist['val_mean_io_u'],'r',label='Validation mean IOU')\n",
    "ax[3].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mri type must one of 1) flair 2) t1 3) t1ce 4) t2 ------- or even 5) seg\n",
    "# returns volume of specified study at `path`\n",
    "def imageLoader(path):\n",
    "    image = nib.load(path).get_fdata()\n",
    "    X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n",
    "    for j in range(VOLUME_SLICES):\n",
    "        X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(image[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
    "        X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
    "\n",
    "        y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n",
    "    return np.array(image)\n",
    "\n",
    "\n",
    "# load nifti file at `path`\n",
    "# and load each slice with mask from volume\n",
    "# choose the mri type & resize to `IMG_SIZE`\n",
    "def loadDataFromDir(path, list_of_files, mriType, n_images):\n",
    "    scans = []\n",
    "    masks = []\n",
    "    for i in list_of_files[:n_images]:\n",
    "        fullPath = glob.glob( i + '/*'+ mriType +'*')[0]\n",
    "        currentScanVolume = imageLoader(fullPath)\n",
    "        currentMaskVolume = imageLoader( glob.glob( i + '/*seg*')[0] ) \n",
    "        # for each slice in 3D volume, find also it's mask\n",
    "        for j in range(0, currentScanVolume.shape[2]):\n",
    "            scan_img = cv2.resize(currentScanVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')\n",
    "            mask_img = cv2.resize(currentMaskVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')\n",
    "            scans.append(scan_img[..., np.newaxis])\n",
    "            masks.append(mask_img[..., np.newaxis])\n",
    "    return np.array(scans, dtype='float32'), np.array(masks, dtype='float32')\n",
    "        \n",
    "#brains_list_test, masks_list_test = loadDataFromDir(VALIDATION_DATASET_PATH, test_directories, \"flair\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise Base Tumor Segmentation Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictByPath(case_path, case):\n",
    "    files = next(os.walk(case_path))[2]\n",
    "    X = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 2))\n",
    "  #  y = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE))\n",
    "    \n",
    "    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_flair.nii');\n",
    "    flair=nib.load(vol_path).get_fdata()\n",
    "    \n",
    "    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_t1ce.nii');\n",
    "    ce=nib.load(vol_path).get_fdata() \n",
    "    \n",
    " #   vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_seg.nii');\n",
    " #   seg=nib.load(vol_path).get_fdata()  \n",
    "\n",
    "    \n",
    "    for j in range(VOLUME_SLICES):\n",
    "        X[j,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n",
    "        X[j,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n",
    " #       y[j,:,:] = cv2.resize(seg[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n",
    "        \n",
    "  #  model.evaluate(x=X,y=y[:,:,:,0], callbacks= callbacks)\n",
    "    return model.predict(X/np.max(X), verbose=1)\n",
    "\n",
    "def showPredictsById(case, start_slice = 60):\n",
    "    path = os.path.join(os.getcwd(), f'BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case[-3:]}')\n",
    "    gt = nib.load(os.path.join(path, f'BraTS20_Training_{case}_seg.nii')).get_fdata()\n",
    "    origImage = nib.load(os.path.join(path, f'BraTS20_Training_{case}_flair.nii')).get_fdata()\n",
    "    p = predictByPath(path,case)\n",
    "\n",
    "    core = p[:,:,:,1]\n",
    "    edema= p[:,:,:,2]\n",
    "    enhancing = p[:,:,:,3]\n",
    "\n",
    "    plt.figure(figsize=(18, 50))\n",
    "    f, axarr = plt.subplots(1,6, figsize = (18, 50)) \n",
    "\n",
    "    for i in range(6): # for each image, add brain background\n",
    "        axarr[i].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\", interpolation='none')\n",
    "    \n",
    "    axarr[0].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\")\n",
    "    axarr[0].title.set_text('Original image flair')\n",
    "    curr_gt=cv2.resize(gt[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_NEAREST)\n",
    "    axarr[1].imshow(curr_gt, cmap=\"Reds\", interpolation='none', alpha=0.3) # ,alpha=0.3,cmap='Reds'\n",
    "    axarr[1].title.set_text('Ground truth')\n",
    "    axarr[2].imshow(p[start_slice,:,:,1:4], cmap=\"Reds\", interpolation='none', alpha=0.3)\n",
    "    axarr[2].title.set_text('all classes')\n",
    "    axarr[3].imshow(edema[start_slice,:,:], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n",
    "    axarr[3].title.set_text(f'{SEGMENT_CLASSES[1]} predicted')\n",
    "    axarr[4].imshow(core[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n",
    "    axarr[4].title.set_text(f'{SEGMENT_CLASSES[2]} predicted')\n",
    "    axarr[5].imshow(enhancing[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n",
    "    axarr[5].title.set_text(f'{SEGMENT_CLASSES[3]} predicted')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "showPredictsById(case=test_ids[0][-3:])\n",
    "showPredictsById(case=test_ids[1][-3:])\n",
    "showPredictsById(case=test_ids[2][-3:])\n",
    "showPredictsById(case=test_ids[3][-3:])\n",
    "showPredictsById(case=test_ids[4][-3:])\n",
    "showPredictsById(case=test_ids[5][-3:])\n",
    "showPredictsById(case=test_ids[6][-3:])\n",
    "\n",
    "\n",
    "# mask = np.zeros((10,10))\n",
    "# mask[3:-3, 3:-3] = 1 # white square in black background\n",
    "# im = mask + np.random.randn(10,10) * 0.01 # random image\n",
    "# masked = np.ma.masked_where(mask == 0, mask)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.imshow(im, 'gray', interpolation='none')\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.imshow(im, 'gray', interpolation='none')\n",
    "# plt.imshow(masked, 'jet', interpolation='none', alpha=0.7)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformal Starts Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = IMG_SIZE * IMG_SIZE * VOLUME_SLICES\n",
    "target_fnr = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conformal_prediction_set(smx_scores, lambda_hat):\n",
    "    \"\"\"\n",
    "    Generates prediction sets based on softmax outputs and a quantile threshold.\n",
    "\n",
    "    Parameters:\n",
    "    - smx_scores: A 2D numpy array of softmax outputs. Each row corresponds to an instance,\n",
    "                  and each column corresponds to a class.\n",
    "    - lambda_hat: The quantile threshold used to determine the prediction sets.\n",
    "\n",
    "    Returns:\n",
    "    - prediction_sets: A boolean 2D numpy array indicating the classes included in the\n",
    "                       prediction set for each instance.\n",
    "    \"\"\"\n",
    "    # Sort the softmax outputs in descending order\n",
    "    val_pi = smx_scores.argsort(1)[:, ::-1]\n",
    "    \n",
    "    # Calculate the cumulative sums of the sorted softmax outputs\n",
    "    val_srt = np.take_along_axis(smx_scores, val_pi, axis=1).cumsum(axis=1)\n",
    "    \n",
    "    # Determine the boundary for each instance's prediction set\n",
    "    exceeds_lambda = val_srt >= lambda_hat\n",
    "    prediction_set_boundaries = np.argmax(exceeds_lambda, axis=1)\n",
    "    \n",
    "    # For instances where lambda_hat is never exceeded, include all classes\n",
    "    all_included = np.all(~exceeds_lambda, axis=1)\n",
    "    prediction_set_boundaries[all_included] = val_srt.shape[1] - 1  # Set to the last index for these cases\n",
    "    \n",
    "    # Initialize the prediction sets array\n",
    "    prediction_sets = np.zeros_like(val_srt, dtype=bool)\n",
    "    \n",
    "    # Generate a mask for values within the prediction set boundaries\n",
    "    col_indices = np.arange(val_srt.shape[1])\n",
    "    within_boundary_mask = col_indices <= prediction_set_boundaries[:, None]\n",
    "    \n",
    "    # Apply the mask according to the sorted indices\n",
    "    prediction_sets[np.arange(val_srt.shape[0])[:, None], val_pi] = within_boundary_mask\n",
    "    \n",
    "    return prediction_sets\n",
    "\n",
    "def fnr_loss(prediction_sets, ground_truth):\n",
    "    \"\"\"\n",
    "    Calculates the False Negative Rate (FNR) given prediction sets and ground truth labels.\n",
    "\n",
    "    Parameters:\n",
    "    - prediction_sets: A boolean 2D numpy array indicating the classes included in the\n",
    "                       prediction set for each instance.\n",
    "    - ground_truth: A 1D numpy array of ground truth class labels.\n",
    "\n",
    "    Returns:\n",
    "    - FNR: The False Negative Rate as a float.\n",
    "    \"\"\"\n",
    "    # False Negatives: Instances where the ground truth is a tumor (1, 2, or 3),\n",
    "    # but the prediction set includes only class 0 (no tumor).\n",
    "    true_positive_rate = np.sum((ground_truth > 0) & np.any(prediction_sets[:, 1:] == True, axis=1)) / np.sum(ground_truth > 0)\n",
    "\n",
    "    return 1 - true_positive_rate if np.sum(ground_truth > 0) > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### small example of how conformal prediction sets are formed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smx_scores = np.array([\n",
    "    [0.9, 0.05, 0.03, 0.02],  # Slice 1: High confidence for class 0 (No tumor)\n",
    "    [0.2, 0.5, 0.2, 0.1],     # Slice 2: Moderate confidence for class 1 (Tumor type 1)\n",
    "    [0.1, 0.2, 0.35, 0.35],   # Slice 3: Close probabilities for classes 2 and 3 (Tumor types 2 and 3)\n",
    "    [0.15, 0.15, 0.2, 0.5]    # Slice 4: Leaning towards class 3 (Tumor type 3), but uncertain\n",
    "])\n",
    "\n",
    "# Set qhat to define our prediction confidence threshold\n",
    "lambda_hat = 0.7  # This means we want at least 60% confidence to include a class in the prediction set\n",
    "\n",
    "# Deploy\n",
    "prediction_sets = conformal_prediction_set(smx_scores, lambda_hat)\n",
    "\n",
    "# Print prediction sets for inspection\n",
    "print(\"Prediction Sets:\")\n",
    "print(prediction_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformal Calibration Starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(case):\n",
    "    path = os.path.join(os.getcwd(), f'BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case[-3:]}')\n",
    "    #original_image = nib.load(os.path.join(path, f'BraTS20_Training_{case[-3:]}_flair.nii')).get_fdata()\n",
    "    ground_truth = nib.load(os.path.join(path, f'BraTS20_Training_{case[-3:]}_seg.nii')).get_fdata()\n",
    "    ground_truth[ground_truth == 4] = 3\n",
    "    ground_truth = cv2.resize(ground_truth, (IMG_SIZE, IMG_SIZE))[:, :, VOLUME_START_AT:VOLUME_START_AT+VOLUME_SLICES]\n",
    "    ground_truth = ground_truth.astype(int)\n",
    "    soft_max = predictByPath(path,case[-3:])\n",
    "    soft_max = np.transpose(soft_max, (1, 2, 0, 3))\n",
    "    return soft_max, ground_truth\n",
    "\n",
    "def process_and_store_data(id_list):\n",
    "    \"\"\"\n",
    "    Process each dataset in id_list and store or return for further processing.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    for case_id in id_list:\n",
    "        sftmax, gt = load_data(case_id[-3:])\n",
    "        \n",
    "        all_data.append((sftmax, gt))\n",
    "        \n",
    "    return all_data\n",
    "\n",
    "conformal_cal_data = process_and_store_data(conformal_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the softmax scores and ground truth labels across all cases\n",
    "cal_smx_scores = np.vstack([sftmax.reshape(-1, sftmax.shape[-1]) for sftmax, _ in conformal_cal_data])\n",
    "cal_gt_labels = np.hstack([gt.flatten() for _, gt in conformal_cal_data])\n",
    "\n",
    "# Calculate calibration scores for the aggregated data\n",
    "cal_pi = cal_smx_scores.argsort(1)[:, ::-1]\n",
    "cal_srt = np.take_along_axis(cal_smx_scores, cal_pi, axis=1).cumsum(axis=1)\n",
    "cal_scores = np.take_along_axis(cal_srt, cal_pi.argsort(axis=1), axis=1)[np.arange(cal_gt_labels.size), cal_gt_labels]\n",
    "\n",
    "# Determine the quantile for lambda_hat that controls the FNR across all data\n",
    "target_fnr = 0.05  # for example\n",
    "n = cal_gt_labels.size\n",
    "true_positive_scores = cal_scores[cal_gt_labels > 0].min(axis=1)\n",
    "q_hat = np.quantile(cal_srt[cal_gt_labels> 0, 1:].min(axis=1), np.ceil((n+1)*(1-target_fnr))/n, interpolation='higher')\n",
    "\n",
    "print(f\"Calibrated lambda_hat for all data: {q_hat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your target FNR and range for lambda values\n",
    "target_fnr = 0.05\n",
    "lambda_values = np.linspace(1, 0, 200)  # Starting from 1 (smallest sets) to 0 (largest sets)\n",
    "\n",
    "# Placeholder for the chosen lambda_hat\n",
    "lambda_hat = 1  # Start with the smallest set (most conservative)\n",
    "\n",
    "# Loop through lambda values from most conservative (small sets) to least (large sets)\n",
    "for lambda_val in lambda_values:\n",
    "    # Generate prediction sets using the current lambda value\n",
    "    prediction_sets = conformal_prediction_set(cal_smx_scores, lambda_val)\n",
    "    \n",
    "    # Compute the FNR for these prediction sets\n",
    "    current_fnr = fnr_loss(prediction_sets, cal_gt_labels)\n",
    "    print(f'{lambda_val} : {current_fnr}')\n",
    "    \n",
    "    # Check if the current FNR is below the target, if so, update lambda_hat and continue\n",
    "    if current_fnr <= target_fnr:\n",
    "        lambda_hat = lambda_val\n",
    "    else:\n",
    "        # If FNR exceeds target, stop the loop; the last lambda_hat is the largest lambda meeting the FNR criterion\n",
    "        break\n",
    "\n",
    "# Print the chosen lambda_hat and the corresponding FNR\n",
    "print(f\"Chosen lambda_hat: {lambda_hat}\")\n",
    "\n",
    "# Assume you have validation softmax outputs (val_smx) and labels (val_labels)\n",
    "# print(f\"Validation FNR at lambda_hat: {fnr_loss(conformal_prediction_set(val_smx, lambda_hat), val_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively lambda hat can be found by using binary search which is more efficient\n",
    "def binary_search_lambda(all_smx_scores, all_gt_labels, target_fnr, low=0, high=1, tol=0.0005):\n",
    "    \"\"\"\n",
    "    Use binary search to find the lambda_hat value that achieves the target FNR.\n",
    "    \"\"\"\n",
    "    while low < high - tol:\n",
    "        mid = (low + high) / 2\n",
    "        prediction_sets = conformal_prediction_set(all_smx_scores, mid)\n",
    "        current_fnr = fnr_loss(prediction_sets, all_gt_labels)\n",
    "\n",
    "        if current_fnr > target_fnr:\n",
    "            low = mid\n",
    "        else:\n",
    "            high = mid\n",
    "\n",
    "    return (low + high) / 2\n",
    "\n",
    "# Calculate the optimal lambda_hat using binary search\n",
    "lambda_hat = binary_search_lambda(all_smx_scores, all_gt_labels, target_fnr)\n",
    "print(f\"Optimized lambda_hat: {lambda_hat}\")\n",
    "print(fnr_loss(conformal_prediction_set(all_smx_scores, lambda_hat), all_gt_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make up space on memory\n",
    "# del conformal_cal_data \n",
    "# del cal_smx_scores\n",
    "# del cal_gt_labels\n",
    "\n",
    "conformal_val_data = process_and_store_data(val_ids)\n",
    "\n",
    "# Flatten the softmax scores and ground truth labels across all cases\n",
    "val_smx_scores = np.vstack([sftmax.reshape(-1, sftmax.shape[-1]) for sftmax, _ in conformal_val_data])\n",
    "val_gt_labels = np.hstack([gt.flatten() for _, gt in conformal_val_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all the FNR for each prediction in the validation set\n",
    "fnr_list = []\n",
    "set_size_fraction_list = []\n",
    "\n",
    "for sftmax, gt in conformal_val_data:\n",
    "    sftmax_flat = sftmax.reshape(-1, sftmax.shape[-1])\n",
    "    gt_flat = gt.flatten()\n",
    "    \n",
    "    prediction_sets = conformal_prediction_set(sftmax_flat, lambda_hat)\n",
    "    fnr = fnr_loss(prediction_sets, gt_flat)\n",
    "    fnr_list.append(fnr)\n",
    "    \n",
    "    # Calculate set size as a fraction of polyp size (assuming 'polyp' is equivalent to tumor)\n",
    "    # This is an example calculation that you will need to adjust based on your actual data\n",
    "    set_size = conformal_prediction_set(sftmax_flat, lambda_hat)[np.sum(conformal_prediction_set(sftmax_flat, lambda_hat)[:,1:],axis=1) > 0].shape[0]  # Sum over classes\n",
    "    polyp_size = np.sum(gt_flat > 0)  # Assuming non-zero labels are tumors\n",
    "    set_size_fraction = set_size / polyp_size\n",
    "    set_size_fraction_list.extend(set_size_fraction[polyp_size > 0])  # Exclude cases without polyps\n",
    "\n",
    "# Generate prediction sets for the validation data using the calibrated lambda_hat\n",
    "val_prediction_sets = conformal_prediction_set(val_smx_scores, lambda_hat)\n",
    "\n",
    "# Calculate the FNR loss on the validation data\n",
    "validation_fnr_loss = fnr_loss(val_prediction_sets, val_gt_labels)\n",
    "\n",
    "print(f\"Validation FNR: {validation_fnr_loss}\")\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'risk': fnr_list,\n",
    "    'set_size_fraction': set_size_fraction_list\n",
    "})\n",
    "\n",
    "# Begin plotting\n",
    "sns.set(palette='pastel', font='serif')\n",
    "sns.set_style('white')\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12,3))\n",
    "\n",
    "# Plot risk histogram (FNR distribution)\n",
    "axs[0].hist(df['risk'].to_numpy(), bins=30, alpha=0.7,  density=True)\n",
    "axs[0].set_xlabel('Risk (False Negative Rate)')\n",
    "axs[0].locator_params(axis='x', nbins=10)\n",
    "axs[0].axvline(x=target_fnr,c='#999999',linestyle='--',alpha=0.7)\n",
    "axs[0].set_ylabel('Density')\n",
    "\n",
    "# Plot set size as fraction of polyp size histogram\n",
    "axs[1].hist(df['set_size_fraction'], bins=np.logspace(np.log10(0.1), np.log10(5), 50), alpha=0.7, density=True)\n",
    "axs[1].set_xlabel('Set size as a fraction of polyp size')\n",
    "axs[1].locator_params(axis='x', nbins=10)\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].set_ylabel('Density')\n",
    "\n",
    "\n",
    "sns.despine(top=True, right=True, ax=axs[0])\n",
    "sns.despine(top=True, right=True, ax=axs[1])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"The mean and standard deviation of the risk over {len(df)} trials are {df['risk'].mean():.4f} and {df['risk'].std():.4f} respectively.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style\n",
    "sns.set(palette='pastel', font='serif')\n",
    "sns.set_style('white')\n",
    "\n",
    "# Begin plotting with the specified figure size and dpi\n",
    "plt.figure(figsize=(8, 6), dpi=300)\n",
    "plt.scatter(df['set_size_fraction'], df['risk'], alpha=0.7)\n",
    "\n",
    "# Setting the scale of x-axis to log scale for set size fractions\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('set size as fraction of polyp size')\n",
    "plt.ylabel('risk (false negative rate)')\n",
    "plt.title('risk and set size')\n",
    "\n",
    "# Remove top and right borders\n",
    "sns.despine()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate prediction sets for the validation data using the calibrated lambda_hat\n",
    "val_prediction_sets = conformal_prediction_set(val_smx_scores, lambda_hat)\n",
    "\n",
    "# Calculate the FNR loss on the validation data\n",
    "validation_fnr_loss = fnr_loss(val_prediction_sets, val_gt_labels)\n",
    "\n",
    "print(f\"Validation FNR: {validation_fnr_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Visualisation tool we build for NN Initial Segmentation + Conformal Uncertainty Quantification\n",
    "\n",
    "Note: there is an error in visual studio code (most likely also in other jupyter notebook IDE's) where files with output larger than 150MB will corrupt the notebook.\n",
    "\n",
    "hence first clear all outputs running the following part.\n",
    "\n",
    "Trust me we have found out the hard way ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Conformal Calibration case\n",
    "case = '004'\n",
    "path = os.path.join(os.getcwd(), f'BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case[-3:]}')\n",
    "cal_gt = nib.load(os.path.join(path, f'BraTS20_Training_{case}_seg.nii')).get_fdata()\n",
    "cal_gt[cal_gt == 4] = 3\n",
    "cal_gt = cv2.resize(cal_gt, (IMG_SIZE, IMG_SIZE))[:, :, VOLUME_START_AT:VOLUME_START_AT+VOLUME_SLICES]\n",
    "cal_gt = cal_gt.astype(int)\n",
    "origImage = nib.load(os.path.join(path, f'BraTS20_Training_{case}_flair.nii')).get_fdata(); origImage = cv2.resize(origImage, (IMG_SIZE, IMG_SIZE))[:, :, VOLUME_START_AT:VOLUME_START_AT+VOLUME_SLICES]\n",
    "\n",
    "cal_smx = predictByPath(path,case)\n",
    "cal_smx = np.transpose(cal_smx, (1, 2, 0, 3)); p = cal_smx\n",
    "# Get scores.\n",
    "cal_smx = cal_smx.reshape(-1, cal_smx.shape[-1])\n",
    "cal_labels = cal_gt.reshape(-1); n=cal_labels.shape[0]\n",
    "cal_pi = cal_smx.argsort(1)[:,::-1] # Sorted indices in descending order of probabilities\n",
    "cal_srt = np.take_along_axis(cal_smx, cal_pi, axis=1).cumsum(axis=1) # Cumulative sums of sorted probabilities\n",
    "cal_scores = np.take_along_axis(cal_srt,cal_pi.argsort(axis=1),axis=1)[range(n),cal_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert probabilities to category assignments\n",
    "category_assignments = np.argmax(p, axis=-1)\n",
    "\n",
    "# Ensure there are non-zero categories\n",
    "if np.all(category_assignments == 0):\n",
    "    raise ValueError(\"All category assignments are 0. No tumor categories to plot.\")\n",
    "\n",
    "\n",
    "# Generate grid coordinates\n",
    "# np.indices will create a set of arrays (one for each dimension), each containing the indices along that dimension\n",
    "x, y, z = np.indices((IMG_SIZE, IMG_SIZE, VOLUME_SLICES))\n",
    "\n",
    "z = z * 128/244\n",
    "# Create a figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Create a single volume with multiple isosurfaces\n",
    "fig.add_trace(go.Volume(\n",
    "    x=x.flatten(), # X coordinates\n",
    "    y=y.flatten(), # Y coordinates\n",
    "    z=z.flatten(), # Z coordinates\n",
    "    value=origImage.flatten(), # Assignments\n",
    "    isomin=1.5,\n",
    "    isomax=4,  # Adjust based on the number of categories; here it's set to include 1-3\n",
    "    opacity=0.1,  # Adjust opacity as needed\n",
    "    surface_count=1,  # One surface for each category\n",
    "    colorscale='Greys',  # Use a perceptually uniform colorscale\n",
    "    name='Brain MRI'\n",
    "))\n",
    "\n",
    "\n",
    "# Create a single volume with multiple isosurfaces\n",
    "fig.add_trace(go.Volume(\n",
    "    x=x.flatten(), # X coordinates\n",
    "    y=y.flatten(), # Y coordinates\n",
    "    z=z.flatten(), # Z coordinates\n",
    "    value=conformal_prediction_set(cal_smx, lambda_hat).reshape(IMG_SIZE, IMG_SIZE, VOLUME_SLICES, -1).sum(axis=-1).flatten(), # Assignments\n",
    "    isomin=1.5,\n",
    "    isomax=4,  # Adjust based on the number of categories; here it's set to include 1-3\n",
    "    opacity=0.5,  # Adjust opacity as needed\n",
    "    surface_count=3,  # One surface for each category\n",
    "    colorscale='Reds',  # Use a perceptually uniform colorscale\n",
    "    name='Conformal Uncertainty'\n",
    "))\n",
    "\n",
    "# Create a single volume with multiple isosurfaces\n",
    "fig.add_trace(go.Volume(\n",
    "    x=x.flatten(), # X coordinates\n",
    "    y=y.flatten(), # Y coordinates\n",
    "    z=z.flatten(), # Z coordinates\n",
    "    value=category_assignments.flatten(), # Assignments\n",
    "    isomin=0.5,\n",
    "    isomax=3.5,  # Adjust based on the number of categories; here it's set to include 1-3\n",
    "    opacity=0.2,  # Adjust opacity as needed\n",
    "    surface_count=3,  # One surface for each category\n",
    "    colorscale='Jet',  # Use a perceptually uniform colorscale\n",
    "    name='Tumor Classification'\n",
    "))\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"3D Volumetric Plot of Brain Tumors\",\n",
    "    scene=dict(\n",
    "        xaxis_title='X Axis',\n",
    "        yaxis_title='Y Axis',\n",
    "        zaxis_title='Z Axis'\n",
    "    ),\n",
    "    width = 1400,\n",
    "    height = 900\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "# fig.write_html(\"3D-Tumor-Volume.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gray volume: the brain of the patient\n",
    "\n",
    "Purple Volume: EDEMA\n",
    "\n",
    "Green Volume: Necrotic / Core\n",
    "\n",
    "### Conformal Volumes (varying degree of uncertainty)\n",
    "White Volume: prediction set contains 2 labels\n",
    "\n",
    "Red Volume: prediction set contains 3 labels\n",
    "\n",
    "Dark Red Volume: prediction set contains all 4 labels\n",
    "\n",
    "Since there is only one 'healthy' label, if the prediction set contains more then one label it contains a tumor label."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
